{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S00LgjhrxG6Q"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eRSYnG5wz8BA"
   },
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7Xva3PaSV2s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aE-l7l7MSkze"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"s3://full-stack-bigdata-datasets/Machine Learning Supervisé/projects/fraudulent_activity/Fraud_Data.csv\")\n",
    "ip_country = pd.read_csv(\"s3://full-stack-bigdata-datasets/Machine Learning Supervisé/projects/fraudulent_activity/IpAddress_to_Country.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ip(arg) :\n",
    "    try :\n",
    "        return ip_country.country[(ip_country.lower_bound_ip_address < arg) & (ip_country.upper_bound_ip_address > arg)].iloc[0]\n",
    "    except IndexError :\n",
    "        return \"Pays inconnu\"  \n",
    "      \n",
    "\n",
    "df1[\"country_name\"] = df1.ip_address.apply(transform_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UjqphXqAxMtl",
    "outputId": "8baff08e-ac94-4a76-ed97-1b90833e3749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151112, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "KRHSmh6dJFHw",
    "outputId": "78155bb7-6bef-4c8f-c7ed-339e797bf149"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Pays inconnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
       "1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
       "2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
       "3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
       "4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
       "\n",
       "       device_id source browser sex  age    ip_address  class   country_name  \n",
       "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0          Japan  \n",
       "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0  United States  \n",
       "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1  United States  \n",
       "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0   Pays inconnu  \n",
       "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0  United States  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "KOZW9hbZw5_1",
    "outputId": "4ef4525d-c381-4887-9396-bb375becbd5f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Pays inconnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           signup_time        purchase_time  purchase_value      device_id  \\\n",
       "0  2015-02-24 22:55:49  2015-04-18 02:47:11              34  QVPSPJUOCKZAR   \n",
       "1  2015-06-07 20:39:50  2015-06-08 01:38:54              16  EOGFQPIZPYXFZ   \n",
       "2  2015-01-01 18:52:44  2015-01-01 18:52:45              15  YSSKYOSJHPPLJ   \n",
       "3  2015-04-28 21:13:25  2015-05-04 13:54:50              44  ATGTXKYKUDUQN   \n",
       "4  2015-07-21 07:09:52  2015-09-09 18:40:53              39  NAUITBZFJKHWW   \n",
       "\n",
       "  source browser sex  age    ip_address  class   country_name  \n",
       "0    SEO  Chrome   M   39  7.327584e+08      0          Japan  \n",
       "1    Ads  Chrome   F   53  3.503114e+08      0  United States  \n",
       "2    SEO   Opera   M   53  2.621474e+09      1  United States  \n",
       "3    SEO  Safari   M   41  3.840542e+09      0   Pays inconnu  \n",
       "4    Ads  Safari   M   45  4.155831e+08      0  United States  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.iloc[:, 1:]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EpPwi9smnMa0"
   },
   "source": [
    "## Date/Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kufGx-KOolUD"
   },
   "outputs": [],
   "source": [
    "df1.signup_time = pd.to_datetime(df1.signup_time, format =\"%Y-%m-%d %H:%M:%S\")\n",
    "df1.purchase_time = pd.to_datetime(df1.purchase_time, format =\"%Y-%m-%d %H:%M:%S\")\n",
    "df1[\"time_delta\"] = (df1.purchase_time - df1.signup_time)/np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "4qgvE3QJpkWD",
    "outputId": "803665ce-b4e7-4ddb-b27a-6c706b44ba64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['signup_time', 'purchase_time', 'purchase_value', 'device_id', 'source',\n",
       "       'browser', 'sex', 'age', 'ip_address', 'class', 'country_name',\n",
       "       'time_delta'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "A7RzJ63kpop1",
    "outputId": "e0021504-0392-4ed8-f035-b9560a4a903e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>y</th>\n",
       "      <th>country_name</th>\n",
       "      <th>time_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>4506682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>17944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Pays inconnu</td>\n",
       "      <td>492085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>4361461.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          signup_time       purchase_time  purchase_value      device_id  \\\n",
       "0 2015-02-24 22:55:49 2015-04-18 02:47:11              34  QVPSPJUOCKZAR   \n",
       "1 2015-06-07 20:39:50 2015-06-08 01:38:54              16  EOGFQPIZPYXFZ   \n",
       "2 2015-01-01 18:52:44 2015-01-01 18:52:45              15  YSSKYOSJHPPLJ   \n",
       "3 2015-04-28 21:13:25 2015-05-04 13:54:50              44  ATGTXKYKUDUQN   \n",
       "4 2015-07-21 07:09:52 2015-09-09 18:40:53              39  NAUITBZFJKHWW   \n",
       "\n",
       "  source browser sex  age    ip_address  y   country_name  time_delta  \n",
       "0    SEO  Chrome   M   39  7.327584e+08  0          Japan   4506682.0  \n",
       "1    Ads  Chrome   F   53  3.503114e+08  0  United States     17944.0  \n",
       "2    SEO   Opera   M   53  2.621474e+09  1  United States         1.0  \n",
       "3    SEO  Safari   M   41  3.840542e+09  0   Pays inconnu    492085.0  \n",
       "4    Ads  Safari   M   45  4.155831e+08  0  United States   4361461.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.rename(columns={\"class\": \"y\", \"x\": \"country_name\"})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "xnOwJMNntX0x",
    "outputId": "83a69a41-ef72-4f5f-bf59-725eaa0856c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>y</th>\n",
       "      <th>country_name</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>4506682.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>17944.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Pays inconnu</td>\n",
       "      <td>492085.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>4361461.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          signup_time       purchase_time  purchase_value      device_id  \\\n",
       "0 2015-02-24 22:55:49 2015-04-18 02:47:11              34  QVPSPJUOCKZAR   \n",
       "1 2015-06-07 20:39:50 2015-06-08 01:38:54              16  EOGFQPIZPYXFZ   \n",
       "2 2015-01-01 18:52:44 2015-01-01 18:52:45              15  YSSKYOSJHPPLJ   \n",
       "3 2015-04-28 21:13:25 2015-05-04 13:54:50              44  ATGTXKYKUDUQN   \n",
       "4 2015-07-21 07:09:52 2015-09-09 18:40:53              39  NAUITBZFJKHWW   \n",
       "\n",
       "  source browser sex  age    ip_address  y   country_name  time_delta  year  \\\n",
       "0    SEO  Chrome   M   39  7.327584e+08  0          Japan   4506682.0  2015   \n",
       "1    Ads  Chrome   F   53  3.503114e+08  0  United States     17944.0  2015   \n",
       "2    SEO   Opera   M   53  2.621474e+09  1  United States         1.0  2015   \n",
       "3    SEO  Safari   M   41  3.840542e+09  0   Pays inconnu    492085.0  2015   \n",
       "4    Ads  Safari   M   45  4.155831e+08  0  United States   4361461.0  2015   \n",
       "\n",
       "   month  \n",
       "0      4  \n",
       "1      6  \n",
       "2      1  \n",
       "3      5  \n",
       "4      9  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['year'] = pd.DatetimeIndex(df1['purchase_time']).year\n",
    "df1['month'] = pd.DatetimeIndex(df1['purchase_time']).month\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151112, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-76e7fc6185f5>:2: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df1.describe(include='all')\n",
      "<ipython-input-16-76e7fc6185f5>:2: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df1.describe(include='all')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>y</th>\n",
       "      <th>country_name</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>1.511120e+05</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112</td>\n",
       "      <td>1.511120e+05</td>\n",
       "      <td>151112.0</td>\n",
       "      <td>151112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>151112</td>\n",
       "      <td>150679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137956</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2015-06-30 03:58:38</td>\n",
       "      <td>2015-07-17 23:22:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ITUMJCKWEYNDD</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>60615</td>\n",
       "      <td>61432</td>\n",
       "      <td>88293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2015-01-01 00:00:42</td>\n",
       "      <td>2015-01-01 00:00:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2015-08-18 04:40:29</td>\n",
       "      <td>2015-12-16 02:56:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.935372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.140704</td>\n",
       "      <td>2.152145e+09</td>\n",
       "      <td>0.093646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.932029e+06</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>6.008629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.322762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.617733</td>\n",
       "      <td>1.248497e+09</td>\n",
       "      <td>0.291336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.126263e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.660637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.209350e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.085934e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.186754e+06</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.154770e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.926346e+06</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.243258e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.644524e+06</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>4.294850e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.036797e+07</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                signup_time        purchase_time  purchase_value  \\\n",
       "count                151112               151112   151112.000000   \n",
       "unique               151112               150679             NaN   \n",
       "top     2015-06-30 03:58:38  2015-07-17 23:22:55             NaN   \n",
       "freq                      1                    3             NaN   \n",
       "first   2015-01-01 00:00:42  2015-01-01 00:00:44             NaN   \n",
       "last    2015-08-18 04:40:29  2015-12-16 02:56:05             NaN   \n",
       "mean                    NaN                  NaN       36.935372   \n",
       "std                     NaN                  NaN       18.322762   \n",
       "min                     NaN                  NaN        9.000000   \n",
       "25%                     NaN                  NaN       22.000000   \n",
       "50%                     NaN                  NaN       35.000000   \n",
       "75%                     NaN                  NaN       49.000000   \n",
       "max                     NaN                  NaN      154.000000   \n",
       "\n",
       "            device_id  source browser     sex            age    ip_address  \\\n",
       "count          151112  151112  151112  151112  151112.000000  1.511120e+05   \n",
       "unique         137956       3       5       2            NaN           NaN   \n",
       "top     ITUMJCKWEYNDD     SEO  Chrome       M            NaN           NaN   \n",
       "freq               20   60615   61432   88293            NaN           NaN   \n",
       "first             NaN     NaN     NaN     NaN            NaN           NaN   \n",
       "last              NaN     NaN     NaN     NaN            NaN           NaN   \n",
       "mean              NaN     NaN     NaN     NaN      33.140704  2.152145e+09   \n",
       "std               NaN     NaN     NaN     NaN       8.617733  1.248497e+09   \n",
       "min               NaN     NaN     NaN     NaN      18.000000  5.209350e+04   \n",
       "25%               NaN     NaN     NaN     NaN      27.000000  1.085934e+09   \n",
       "50%               NaN     NaN     NaN     NaN      33.000000  2.154770e+09   \n",
       "75%               NaN     NaN     NaN     NaN      39.000000  3.243258e+09   \n",
       "max               NaN     NaN     NaN     NaN      76.000000  4.294850e+09   \n",
       "\n",
       "                    y   country_name    time_delta      year          month  \n",
       "count   151112.000000         151112  1.511120e+05  151112.0  151112.000000  \n",
       "unique            NaN            182           NaN       NaN            NaN  \n",
       "top               NaN  United States           NaN       NaN            NaN  \n",
       "freq              NaN          58049           NaN       NaN            NaN  \n",
       "first             NaN            NaN           NaN       NaN            NaN  \n",
       "last              NaN            NaN           NaN       NaN            NaN  \n",
       "mean         0.093646            NaN  4.932029e+06    2015.0       6.008629  \n",
       "std          0.291336            NaN  3.126263e+06       0.0       2.660637  \n",
       "min          0.000000            NaN  1.000000e+00    2015.0       1.000000  \n",
       "25%          0.000000            NaN  2.186754e+06    2015.0       4.000000  \n",
       "50%          0.000000            NaN  4.926346e+06    2015.0       6.000000  \n",
       "75%          0.000000            NaN  7.644524e+06    2015.0       8.000000  \n",
       "max          1.000000            NaN  1.036797e+07    2015.0      12.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "df1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>y</th>\n",
       "      <th>country_name</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>4506682.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>17944.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>Pays inconnu</td>\n",
       "      <td>492085.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>4361461.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_value source browser sex  age  y   country_name  time_delta  month\n",
       "0              34    SEO  Chrome   M   39  0          Japan   4506682.0      4\n",
       "1              16    Ads  Chrome   F   53  0  United States     17944.0      6\n",
       "2              15    SEO   Opera   M   53  1  United States         1.0      1\n",
       "3              44    SEO  Safari   M   41  0   Pays inconnu    492085.0      5\n",
       "4              39    Ads  Safari   M   45  0  United States   4361461.0      9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns with too many unique values\n",
    "df1 = df1.drop(['signup_time', 'purchase_time', 'device_id'], axis=1)\n",
    "\n",
    "# Drop ip address (not useful as raw number, we will rather use the country_name deduced from the ip)\n",
    "df1 = df1.drop(['ip_address'], axis=1)\n",
    "\n",
    "# Drop year (because it's always 2015)\n",
    "df1 = df1.drop(['year'], axis=1)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States     58049\n",
       "Pays inconnu      21966\n",
       "China             12038\n",
       "Japan              7306\n",
       "United Kingdom     4490\n",
       "                  ...  \n",
       "Cape Verde            1\n",
       "Madagascar            1\n",
       "Nauru                 1\n",
       "Yemen                 1\n",
       "Tajikistan            1\n",
       "Name: country_name, Length: 182, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['country_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States' 'Pays inconnu' 'China' 'Japan' 'United Kingdom'\n",
      " 'Korea Republic of' 'Germany' 'France' 'Canada' 'Brazil' 'Italy'\n",
      " 'Australia' 'Netherlands' 'Russian Federation' 'India'\n",
      " 'Taiwan; Republic of China (ROC)' 'Mexico' 'Sweden' 'Spain'\n",
      " 'South Africa' 'Switzerland' 'Poland' 'Argentina' 'Indonesia' 'Norway'\n",
      " 'Colombia' 'Turkey' 'Viet Nam' 'Romania' 'Denmark' 'Hong Kong' 'Finland'\n",
      " 'Austria' 'Ukraine' 'Chile' 'Belgium' 'Iran (ISLAMIC Republic Of)'\n",
      " 'Egypt' 'Czech Republic' 'Thailand' 'New Zealand' 'Israel' 'Saudi Arabia'\n",
      " 'Venezuela' 'Ireland' 'European Union' 'Greece' 'Portugal' 'Hungary'\n",
      " 'Malaysia' 'Singapore' 'Pakistan' 'Philippines' 'Bulgaria' 'Morocco'\n",
      " 'Algeria' 'Peru' 'Tunisia' 'United Arab Emirates' 'Ecuador' 'Lithuania'\n",
      " 'Seychelles' 'Kenya' 'Kazakhstan' 'Costa Rica' 'Kuwait' 'Slovenia'\n",
      " 'Slovakia (SLOVAK Republic)' 'Uruguay' 'Croatia (LOCAL Name: Hrvatska)'\n",
      " 'Luxembourg' 'Belarus' 'Serbia' 'Nigeria' 'Latvia' 'Panama' 'Bolivia'\n",
      " 'Dominican Republic']\n"
     ]
    }
   ],
   "source": [
    "country_counts = df1['country_name'].value_counts()\n",
    "print(country_counts[country_counts > 50].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop lines with rare values of country_name (< 50 occurences)\n",
    "country_counts = df1['country_name'].value_counts()\n",
    "to_keep = country_counts[country_counts > 50].index.values\n",
    "df1 = df1.loc[df1['country_name'].isin(to_keep),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "...Done.\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: y, dtype: int64\n",
      "\n",
      "   purchase_value source browser sex  age   country_name  time_delta  month\n",
      "0              34    SEO  Chrome   M   39          Japan   4506682.0      4\n",
      "1              16    Ads  Chrome   F   53  United States     17944.0      6\n",
      "2              15    SEO   Opera   M   53  United States         1.0      1\n",
      "3              44    SEO  Safari   M   41   Pays inconnu    492085.0      5\n",
      "4              39    Ads  Safari   M   45  United States   4361461.0      9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "target_name = 'y'\n",
    "\n",
    "print(\"Separating labels from features...\")\n",
    "Y = df1.loc[:,target_name]\n",
    "X = df1.loc[:,[c for c in df1.columns if c!=target_name]] \n",
    "print(\"...Done.\")\n",
    "print(Y.head())\n",
    "print()\n",
    "print(X.head())\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[[34 'SEO' 'Chrome' 'M' 39 'Japan' 4506682.0 4]\n",
      " [16 'Ads' 'Chrome' 'F' 53 'United States' 17944.0 6]\n",
      " [15 'SEO' 'Opera' 'M' 53 'United States' 1.0 1]\n",
      " [44 'SEO' 'Safari' 'M' 41 'Pays inconnu' 492085.0 5]\n",
      " [39 'Ads' 'Safari' 'M' 45 'United States' 4361461.0 9]]\n",
      "\n",
      "[0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X = X.values\n",
    "Y = Y.tolist()\n",
    "print(\"...Done\")\n",
    "print(X[0:5,:])\n",
    "print()\n",
    "print(Y[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset into train set & test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y) # stratified splitting because we have an imbalanced dataset !!\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing preprocessings on train set...\n",
      "[[29 'SEO' 'FireFox' 'F' 24 'Japan' 399081.0 5]\n",
      " [19 'SEO' 'IE' 'M' 30 'United States' 6545091.0 10]\n",
      " [52 'Direct' 'IE' 'M' 37 'Pays inconnu' 1.0 1]\n",
      " [44 'Direct' 'Chrome' 'F' 31 'United States' 261978.0 5]\n",
      " [16 'Direct' 'Chrome' 'F' 42 'United States' 2949385.0 6]]\n",
      "...Done.\n",
      "  (0, 0)\t-0.43296254252665767\n",
      "  (0, 1)\t-1.0591256639796414\n",
      "  (0, 2)\t-1.4478388621940075\n",
      "  (0, 3)\t-0.3783695098615592\n",
      "  (0, 5)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 43)\t1.0\n",
      "  (1, 0)\t-0.9785247924444799\n",
      "  (1, 1)\t-0.36227925966760166\n",
      "  (1, 2)\t0.5175229812597267\n",
      "  (1, 3)\t1.5001657574425975\n",
      "  (1, 5)\t1.0\n",
      "  (1, 7)\t1.0\n",
      "  (1, 10)\t1.0\n",
      "  (1, 84)\t1.0\n",
      "  (2, 0)\t0.8218306322843335\n",
      "  (2, 1)\t0.450708212029778\n",
      "  (2, 2)\t-1.5754560649784994\n",
      "  (2, 3)\t-1.8811977237048847\n",
      "  (2, 4)\t1.0\n",
      "  (2, 7)\t1.0\n",
      "  (2, 10)\t1.0\n",
      "  (2, 60)\t1.0\n",
      "  (3, 0)\t0.3853808323500757\n",
      "  (3, 1)\t-0.24613819228226172\n",
      "  (3, 2)\t-1.491681453537503\n",
      "  (3, 3)\t-0.3783695098615592\n",
      "  (3, 4)\t1.0\n",
      "  (3, 84)\t1.0\n",
      "  (4, 0)\t-1.1421934674198266\n",
      "  (4, 1)\t1.0314135489564777\n",
      "  (4, 2)\t-0.6323064808917589\n",
      "  (4, 3)\t-0.002662456400727865\n",
      "  (4, 4)\t1.0\n",
      "  (4, 84)\t1.0\n",
      "\n",
      "Performing preprocessings on test set...\n",
      "[[18 'SEO' 'Safari' 'M' 27 'United States' 3410639.0 7]\n",
      " [37 'SEO' 'IE' 'F' 41 'Japan' 2885454.0 5]\n",
      " [30 'Ads' 'IE' 'F' 30 'United States' 115887.0 3]\n",
      " [10 'Ads' 'Chrome' 'M' 29 'Brazil' 4886848.0 6]\n",
      " [43 'Ads' 'Chrome' 'M' 44 'Sweden' 3754382.0 6]]\n",
      "...Done.\n",
      "  (0, 0)\t-1.0330810174362621\n",
      "  (0, 1)\t-0.7107024618236215\n",
      "  (0, 2)\t-0.4848073698033603\n",
      "  (0, 3)\t0.37304459706010346\n",
      "  (0, 5)\t1.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 10)\t1.0\n",
      "  (0, 84)\t1.0\n",
      "  (1, 0)\t0.003487257407600134\n",
      "  (1, 1)\t0.9152724815711378\n",
      "  (1, 2)\t-0.6527502400157826\n",
      "  (1, 3)\t-0.3783695098615592\n",
      "  (1, 5)\t1.0\n",
      "  (1, 7)\t1.0\n",
      "  (1, 43)\t1.0\n",
      "  (2, 0)\t-0.3784063175348754\n",
      "  (2, 1)\t-0.36227925966760166\n",
      "  (2, 2)\t-1.538398214016578\n",
      "  (2, 3)\t-1.1297836167832218\n",
      "  (2, 7)\t1.0\n",
      "  (2, 84)\t1.0\n",
      "  (3, 0)\t-1.46953081737052\n",
      "  (3, 1)\t-0.47842032705294163\n",
      "  (3, 2)\t-0.012747473779274208\n",
      "  (3, 3)\t-0.002662456400727865\n",
      "  (3, 10)\t1.0\n",
      "  (3, 17)\t1.0\n",
      "  (4, 0)\t0.33082460735829344\n",
      "  (4, 1)\t1.2636956837271576\n",
      "  (4, 2)\t-0.3748857497353297\n",
      "  (4, 3)\t-0.002662456400727865\n",
      "  (4, 10)\t1.0\n",
      "  (4, 75)\t1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline for numeric features\n",
    "numeric_features = [0, 4, 6, 7] # Positions of numeric columns in X_train/X_test\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create pipeline for categorical features\n",
    "categorical_features = [1, 2, 3, 5] # Positions of categorical columns in X_train/X_test\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Preprocessings on train set\n",
    "print(\"Performing preprocessings on train set...\")\n",
    "print(X_train[0:5,:])\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "print('...Done.')\n",
    "print(X_train[0:5,:])\n",
    "print()\n",
    "\n",
    "# Preprocessings on test set\n",
    "print(\"Performing preprocessings on test set...\")\n",
    "print(X_test[0:5,:])\n",
    "X_test = preprocessor.transform(X_test) # Don't fit again !! The test set is used for validating decisions\n",
    "print('...Done.')\n",
    "print(X_test[0:5,:])\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "...Done.\n",
      "Predictions on training set...\n",
      "...Done.\n",
      "[1 0 1 1 0]\n",
      "\n",
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 1 0 0]\n",
      "\n",
      "f1-score on training set :  0.3108795485903746\n",
      "f1-score on test set :  0.3051717004551096\n"
     ]
    }
   ],
   "source": [
    "# Train baseline model\n",
    "model = LogisticRegression(class_weight = 'balanced', max_iter = 1000) # change value of max_iter to avoid solver warning\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, Y_train) # Training is always done on train set !!\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = model.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred[0:5])\n",
    "print()\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = model.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred[0:5])\n",
    "print()\n",
    "\n",
    "# Print scores\n",
    "print(\"f1-score on training set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... max_depth=4, n_estimators=100, total=   3.1s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... max_depth=4, n_estimators=100, total=   3.2s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=100, total=   3.2s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=100, total=   2.9s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=100, total=   2.8s\n",
      "[CV] max_depth=4, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=120, total=   3.5s\n",
      "[CV] max_depth=4, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=120, total=   3.5s\n",
      "[CV] max_depth=4, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=120, total=   3.6s\n",
      "[CV] max_depth=4, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=120, total=   3.6s\n",
      "[CV] max_depth=4, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=120, total=   3.4s\n",
      "[CV] max_depth=4, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=140, total=   4.2s\n",
      "[CV] max_depth=4, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=140, total=   4.0s\n",
      "[CV] max_depth=4, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=140, total=   3.9s\n",
      "[CV] max_depth=4, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=140, total=   4.0s\n",
      "[CV] max_depth=4, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=140, total=   4.2s\n",
      "[CV] max_depth=4, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=160, total=   4.7s\n",
      "[CV] max_depth=4, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=160, total=   4.6s\n",
      "[CV] max_depth=4, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=160, total=   4.5s\n",
      "[CV] max_depth=4, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=160, total=   5.1s\n",
      "[CV] max_depth=4, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=160, total=   4.5s\n",
      "[CV] max_depth=4, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=180, total=   5.1s\n",
      "[CV] max_depth=4, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=180, total=   5.2s\n",
      "[CV] max_depth=4, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=180, total=   5.0s\n",
      "[CV] max_depth=4, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=180, total=   5.7s\n",
      "[CV] max_depth=4, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=180, total=   5.2s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=100, total=   4.5s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=100, total=   5.1s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=100, total=   4.0s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=100, total=   3.9s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=100, total=   4.1s\n",
      "[CV] max_depth=6, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=120, total=   4.8s\n",
      "[CV] max_depth=6, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=120, total=   4.6s\n",
      "[CV] max_depth=6, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=120, total=   4.5s\n",
      "[CV] max_depth=6, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=120, total=   4.7s\n",
      "[CV] max_depth=6, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=120, total=   4.9s\n",
      "[CV] max_depth=6, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=140, total=   5.4s\n",
      "[CV] max_depth=6, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=140, total=   5.7s\n",
      "[CV] max_depth=6, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=140, total=   5.3s\n",
      "[CV] max_depth=6, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=140, total=   5.1s\n",
      "[CV] max_depth=6, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=140, total=   5.3s\n",
      "[CV] max_depth=6, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=160, total=   6.4s\n",
      "[CV] max_depth=6, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=160, total=   6.1s\n",
      "[CV] max_depth=6, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=160, total=   6.2s\n",
      "[CV] max_depth=6, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=160, total=   6.4s\n",
      "[CV] max_depth=6, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=160, total=   6.5s\n",
      "[CV] max_depth=6, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=180, total=   7.0s\n",
      "[CV] max_depth=6, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=180, total=   7.3s\n",
      "[CV] max_depth=6, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=180, total=   8.1s\n",
      "[CV] max_depth=6, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=180, total=   7.5s\n",
      "[CV] max_depth=6, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=6, n_estimators=180, total=   7.0s\n",
      "[CV] max_depth=8, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=100, total=   5.1s\n",
      "[CV] max_depth=8, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=100, total=   5.4s\n",
      "[CV] max_depth=8, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=100, total=   5.3s\n",
      "[CV] max_depth=8, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=100, total=   5.3s\n",
      "[CV] max_depth=8, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=100, total=   5.7s\n",
      "[CV] max_depth=8, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=120, total=   6.6s\n",
      "[CV] max_depth=8, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=120, total=   6.7s\n",
      "[CV] max_depth=8, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=120, total=   5.9s\n",
      "[CV] max_depth=8, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=120, total=   6.4s\n",
      "[CV] max_depth=8, n_estimators=120 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=120, total=   6.0s\n",
      "[CV] max_depth=8, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=140, total=   7.4s\n",
      "[CV] max_depth=8, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=140, total=   6.9s\n",
      "[CV] max_depth=8, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=140, total=   7.3s\n",
      "[CV] max_depth=8, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=140, total=   7.3s\n",
      "[CV] max_depth=8, n_estimators=140 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=140, total=   6.9s\n",
      "[CV] max_depth=8, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=160, total=   8.3s\n",
      "[CV] max_depth=8, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=160, total=   8.3s\n",
      "[CV] max_depth=8, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=160, total=   8.5s\n",
      "[CV] max_depth=8, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=160, total=   8.2s\n",
      "[CV] max_depth=8, n_estimators=160 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=160, total=   8.1s\n",
      "[CV] max_depth=8, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=180, total=   9.7s\n",
      "[CV] max_depth=8, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=180, total=   9.3s\n",
      "[CV] max_depth=8, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=180, total=   9.4s\n",
      "[CV] max_depth=8, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=180, total=   8.9s\n",
      "[CV] max_depth=8, n_estimators=180 ...................................\n",
      "[CV] .................... max_depth=8, n_estimators=180, total=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n",
      "Best hyperparameters : \n",
      "{'max_depth': 4, 'n_estimators': 120}\n",
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 1 0 0]\n",
      "\n",
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 0 0]\n",
      "\n",
      "f1-score on training set :  0.6991973205520587\n",
      "f1-score on test set :  0.7023041474654378\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest with grid search\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 120, 140, 160, 180],\n",
    "    'max_depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(rf, param_grid = params, verbose=2)\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, Y_train) # Training is always done on train set !!\n",
    "print(\"...Done.\")\n",
    "\n",
    "print(\"Best hyperparameters : \")\n",
    "print(model.best_params_)\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = model.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred[0:5])\n",
    "print()\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = model.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred[0:5])\n",
    "print()\n",
    "\n",
    "# Print scores\n",
    "print(\"f1-score on training set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The f1-score has been multiplied by a factor 2 by introducing non-linearities in the model ! Combined with the grid_search, we converged to a model with quite good performances and no overfitting. Let's have a look to the confusion matrix and other classification scores :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Compute confusion matrix to evaluate the accuracy of a classification.\n",
       "\n",
       "By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
       "is equal to the number of observations known to be in group :math:`i` and\n",
       "predicted to be in group :math:`j`.\n",
       "\n",
       "Thus in binary classification, the count of true negatives is\n",
       ":math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
       ":math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
       "\n",
       "Read more in the :ref:`User Guide <confusion_matrix>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "y_true : array-like of shape (n_samples,)\n",
       "    Ground truth (correct) target values.\n",
       "\n",
       "y_pred : array-like of shape (n_samples,)\n",
       "    Estimated targets as returned by a classifier.\n",
       "\n",
       "labels : array-like of shape (n_classes), default=None\n",
       "    List of labels to index the matrix. This may be used to reorder\n",
       "    or select a subset of labels.\n",
       "    If ``None`` is given, those that appear at least once\n",
       "    in ``y_true`` or ``y_pred`` are used in sorted order.\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "\n",
       "normalize : {'true', 'pred', 'all'}, default=None\n",
       "    Normalizes confusion matrix over the true (rows), predicted (columns)\n",
       "    conditions or all the population. If None, confusion matrix will not be\n",
       "    normalized.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "C : ndarray of shape (n_classes, n_classes)\n",
       "    Confusion matrix whose i-th row and j-th\n",
       "    column entry indicates the number of\n",
       "    samples with true label being i-th class\n",
       "    and prediced label being j-th class.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] `Wikipedia entry for the Confusion matrix\n",
       "       <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
       "       (Wikipedia and other references may use a different\n",
       "       convention for axes)\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.metrics import confusion_matrix\n",
       ">>> y_true = [2, 0, 2, 2, 0, 1]\n",
       ">>> y_pred = [0, 0, 2, 2, 0, 2]\n",
       ">>> confusion_matrix(y_true, y_pred)\n",
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])\n",
       "\n",
       ">>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
       ">>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
       ">>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])\n",
       "\n",
       "In the binary case, we can extract true positives, etc as follows:\n",
       "\n",
       ">>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
       ">>> (tn, fp, fn, tp)\n",
       "(0, 2, 1, 1)\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train set ---\n",
      "Precision :  1.0\n",
      "Recall :  0.5375122081150671\n",
      "\n",
      "[[108683      0]\n",
      " [  5209   6054]]\n",
      "\n",
      "--- Test set ---\n",
      "Precision :  1.0\n",
      "Recall :  0.5411931818181818\n",
      "\n",
      "[[27171     0]\n",
      " [ 1292  1524]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "print('--- Train set ---')\n",
    "print('Precision : ', precision_score(Y_train, Y_train_pred))\n",
    "print('Recall : ', recall_score(Y_train, Y_train_pred))\n",
    "print()\n",
    "print(confusion_matrix(Y_train, Y_train_pred))\n",
    "print()\n",
    "print('--- Test set ---')\n",
    "print('Precision : ', precision_score(Y_test, Y_test_pred))\n",
    "print('Recall : ', recall_score(Y_test, Y_test_pred))\n",
    "print()\n",
    "print(confusion_matrix(Y_test, Y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the scores\n",
    "\n",
    "* The precision represents the \"purity\" of the predictions \"1\". In other words, it's the ratio of examples being predicted as 1s that are indeed true 1s : $P = \\frac{TP}{TP + FP}$ \n",
    "* The recall represents the ability to detect the true \"1\". It's the ratio of examples that are true 1s and have been predicted as 1s : $R = \\frac{TP}{TP + FN}$ \n",
    "* From the formulae above, one can see the the precision is maximal when there are no false positives, and the recall is maximal when there are no false negatives\n",
    "\n",
    "#### What does that mean in the context of fraud detection ?\n",
    "\n",
    "* False positives represent transactions that are reported as frauds but in fact aren't\n",
    "* False negatives represent frauds that are not detected (this is the kind of error that we want to avoid)\n",
    "* In this case, we would like to detect as much frauds as possible while having a number of false positives that is as close as possible to 0 (because we want to avoid fake alerts that would be time-consuming for the company)\n",
    "\n",
    "#### What is our model doing here ?\n",
    "* Our model's precision is perfect (P=1) which means there are no false positives\n",
    "* Our model's recall is lower (R=0.5) which means that we detect only 50% of the frauds\n",
    "\n",
    "#### Is it satisfying ?\n",
    "Yes, with this model we would detect 50% of the frauds without making any false alert (which is way better than detecting no frauds at all)\n",
    "\n",
    "#### Next steps\n",
    "To explain the model to your boss, you can :\n",
    "* Plot the feature importances in your model\n",
    "* Make some viz of the different features X and see if it changes whether Y=0 or Y=1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nF_HnzRzaeuX",
    "qhPworq7VAY8",
    "394M9Ix055lp",
    "bxzZgHty6Ab9",
    "rmcCQhMqq29y",
    "tScKdounrlF3"
   ],
   "machine_shape": "hm",
   "name": "Copy of S4 - Fraudulent activities v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
